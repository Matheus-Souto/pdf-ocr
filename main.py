from fastapi import FastAPI, File, UploadFile, HTTPException, BackgroundTasks, Form
from fastapi.responses import FileResponse, StreamingResponse
from fastapi.staticfiles import StaticFiles
import pytesseract
import fitz  # PyMuPDF
from PIL import Image, ImageEnhance, ImageFilter, ImageOps
import io
import os
import tempfile
import uuid
from typing import List, Tuple, Dict, Optional
import uvicorn
import json
import asyncio
import cv2
import numpy as np
import datetime
import time
import re
from scipy import ndimage
from skimage import morphology, filters, measure
from collections import Counter
import math
import shutil
from pdf2image import convert_from_path
from uuid import uuid4
from difflib import SequenceMatcher
import gc

# Imports opcionais de AI/ML
try:
    import torch
    import torchvision.transforms as transforms
    TORCH_AVAILABLE = True
except ImportError:
    TORCH_AVAILABLE = False
    print("‚ö†Ô∏è PyTorch n√£o dispon√≠vel - funcionalidades TrOCR desabilitadas")

try:
    from transformers import TrOCRProcessor, VisionEncoderDecoderModel
    TRANSFORMERS_AVAILABLE = True
except ImportError:
    TRANSFORMERS_AVAILABLE = False
    print("‚ö†Ô∏è Transformers n√£o dispon√≠vel - funcionalidades TrOCR desabilitadas")

try:
    import easyocr
    EASYOCR_AVAILABLE = True
except ImportError:
    EASYOCR_AVAILABLE = False
    print("‚ö†Ô∏è EasyOCR n√£o dispon√≠vel - funcionalidades EasyOCR desabilitadas")

app = FastAPI(
    title="PDF OCR API Avan√ßada",
    description="API para converter PDFs n√£o pesquis√°veis em PDFs pesquis√°veis usando OCR com m√°xima precis√£o e t√©cnicas avan√ßadas",
    version="2.0.0"
)

# Montar arquivos est√°ticos (para servir exemplo_progress.html)
app.mount("/static", StaticFiles(directory="."), name="static")

# Configurar o caminho do Tesseract (ajuste conforme sua instala√ß√£o)
# Para Windows, descomente e ajuste o caminho:
# pytesseract.pytesseract.tesseract_cmd = r'C:\Program Files\Tesseract-OCR\tesseract.exe'

# Vari√°veis globais para engines (ser√£o inicializadas no startup)
easyocr_reader = None
trocr_processor = None
trocr_model = None

# Flag para indicar se engines est√£o sendo carregadas
engines_loading = False

@app.on_event("startup")
async def startup_event():
    """Inicializa as engines de OCR apenas uma vez durante o startup."""
    global easyocr_reader, trocr_processor, trocr_model
    
    print("üöÄ INICIANDO SISTEMA PDF OCR API...")
    print(f"üîß EASYOCR_AVAILABLE: {EASYOCR_AVAILABLE}")
    print(f"üîß TRANSFORMERS_AVAILABLE: {TRANSFORMERS_AVAILABLE}")
    print(f"üîß TORCH_AVAILABLE: {TORCH_AVAILABLE}")
    
    # FOR√áAR configura√ß√£o de cache unificado
    print("üîß FOR√áANDO CONFIGURA√á√ÉO DE CACHE UNIFICADO...")
    os.environ['TORCH_HOME'] = '/app/.cache/torch'
    os.environ['TRANSFORMERS_CACHE'] = '/app/.cache/transformers'
    os.environ['HF_HOME'] = '/app/.cache/huggingface'
    os.environ['HF_DATASETS_CACHE'] = '/app/.cache/huggingface/datasets'
    os.environ['EASYOCR_MODULE_PATH'] = '/app/.cache/easyocr'
    os.environ['EASYOCR_DOWNLOAD_PATH'] = '/app/.cache/easyocr'
    
    # Criar diret√≥rios se n√£o existirem
    cache_dirs = [
        '/app/.cache',
        '/app/.cache/torch',
        '/app/.cache/transformers', 
        '/app/.cache/huggingface',
        '/app/.cache/huggingface/datasets',
        '/app/.cache/easyocr'
    ]
    
    for cache_dir in cache_dirs:
        os.makedirs(cache_dir, exist_ok=True)
        print(f"  ‚úÖ Criado/verificado: {cache_dir}")
    
    # Mostrar configura√ß√µes de cache AP√ìS corre√ß√£o
    print("üìÅ CONFIGURA√á√ïES DE CACHE (CORRIGIDAS):")
    print(f"  üóÇÔ∏è TORCH_HOME: {os.environ.get('TORCH_HOME')}")
    print(f"  üóÇÔ∏è TRANSFORMERS_CACHE: {os.environ.get('TRANSFORMERS_CACHE')}")
    print(f"  üóÇÔ∏è HF_HOME: {os.environ.get('HF_HOME')}")
    print(f"  üóÇÔ∏è EASYOCR_MODULE_PATH: {os.environ.get('EASYOCR_MODULE_PATH')}")
    
    # Verificar estado dos diret√≥rios
    for cache_dir in cache_dirs:
        if os.path.exists(cache_dir):
            files = os.listdir(cache_dir)
            print(f"  üìÇ {cache_dir}: {len(files)} arquivos")
        else:
            print(f"  ‚ùå {cache_dir}: n√£o existe")
    
    # Inicializa√ß√£o LAZY - n√£o carregar engines no startup para evitar timeout
    print("‚ö° Inicializa√ß√£o LAZY ativada - engines ser√£o carregadas sob demanda")
    print("‚úÖ API pronta para receber requisi√ß√µes!")
    
    # # Inicializar EasyOCR
    # if EASYOCR_AVAILABLE:
    #     try:
    #         print("‚è≥ Carregando EasyOCR...")
    #         easyocr_reader = easyocr.Reader(['pt', 'en'], gpu=False)  # Portugu√™s e Ingl√™s
    #         print("‚úÖ EasyOCR inicializado com sucesso")
    #     except Exception as e:
    #         easyocr_reader = None
    #         print(f"‚ùå EasyOCR n√£o p√¥de ser inicializado: {e}")
    # else:
    #     easyocr_reader = None
    #     print("‚ö†Ô∏è EasyOCR n√£o dispon√≠vel - pacote n√£o instalado")

    # # Inicializar TrOCR
    # if TRANSFORMERS_AVAILABLE and TORCH_AVAILABLE:
    #     try:
    #         print("‚è≥ Carregando TrOCR...")
    #         trocr_processor = TrOCRProcessor.from_pretrained("microsoft/trocr-base-handwritten")
    #         trocr_model = VisionEncoderDecoderModel.from_pretrained("microsoft/trocr-base-handwritten")
    #         print("‚úÖ TrOCR inicializado com sucesso")
    #     except Exception as e:
    #         trocr_processor = None
    #         trocr_model = None
    #         print(f"‚ùå TrOCR n√£o p√¥de ser inicializado: {e}")
    # else:
    #     trocr_processor = None
    #     trocr_model = None
    #     print("‚ö†Ô∏è TrOCR n√£o dispon√≠vel - pacotes PyTorch/Transformers n√£o instalados")

# Criar diret√≥rio tempor√°rio se n√£o existir
os.makedirs("temp", exist_ok=True)

def detect_text_orientation(image: np.ndarray) -> float:
    """
    Detecta a orienta√ß√£o do texto na imagem usando an√°lise de gradientes.
    
    Returns:
        float: √Çngulo de rota√ß√£o necess√°rio em graus
    """
    try:
        # Converter para escala de cinza se necess√°rio
        if len(image.shape) == 3:
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        else:
            gray = image.copy()
        
        # Aplicar filtro para real√ßar bordas de texto
        edges = cv2.Canny(gray, 50, 150, apertureSize=3)
        
        # Detectar linhas usando transformada de Hough
        lines = cv2.HoughLines(edges, 1, np.pi/180, threshold=100)
        
        if lines is not None:
            angles = []
            for line in lines[:20]:  # Analisar apenas as primeiras 20 linhas
                # Corrigir o desempacotamento - cv2.HoughLines retorna array com shape (n, 1, 2)
                rho, theta = line[0]
                angle = theta * 180 / np.pi
                if angle > 90:
                    angle -= 180
                angles.append(angle)
            
            if angles:
                # Usar o √¢ngulo mais comum
                angle_counts = Counter([round(a, 1) for a in angles])
                most_common_angle = angle_counts.most_common(1)[0][0]
                return most_common_angle
    
    except Exception as e:
        print(f"Erro na detec√ß√£o de orienta√ß√£o: {e}")
    
    return 0.0

def correct_skew(image: np.ndarray, angle: float) -> np.ndarray:
    """
    Corrige a inclina√ß√£o da imagem.
    
    Args:
        image: Imagem a ser corrigida
        angle: √Çngulo de rota√ß√£o em graus
    
    Returns:
        Imagem corrigida
    """
    if abs(angle) < 0.5:  # N√£o corrigir se o √¢ngulo for muito pequeno
        return image
    
    # Obter dimens√µes da imagem
    (h, w) = image.shape[:2]
    center = (w // 2, h // 2)
    
    # Criar matriz de rota√ß√£o
    rotation_matrix = cv2.getRotationMatrix2D(center, angle, 1.0)
    
    # Calcular novas dimens√µes ap√≥s rota√ß√£o
    cos = np.abs(rotation_matrix[0, 0])
    sin = np.abs(rotation_matrix[0, 1])
    new_w = int((h * sin) + (w * cos))
    new_h = int((h * cos) + (w * sin))
    
    # Ajustar matriz de rota√ß√£o para centralizar a imagem
    rotation_matrix[0, 2] += (new_w / 2) - center[0]
    rotation_matrix[1, 2] += (new_h / 2) - center[1]
    
    # Aplicar rota√ß√£o
    rotated = cv2.warpAffine(image, rotation_matrix, (new_w, new_h), 
                            flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)
    
    return rotated

def detect_text_regions(image: np.ndarray) -> List[Tuple[int, int, int, int]]:
    """
    Detecta regi√µes de texto na imagem usando an√°lise morfol√≥gica.
    
    Returns:
        Lista de ret√¢ngulos (x, y, w, h) contendo texto
    """
    try:
        # Converter para escala de cinza
        if len(image.shape) == 3:
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        else:
            gray = image.copy()
        
        # Aplicar threshold adaptativo
        binary = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, 
                                     cv2.THRESH_BINARY_INV, 11, 2)
        
        # Criar kernel para opera√ß√µes morfol√≥gicas
        kernel_horizontal = cv2.getStructuringElement(cv2.MORPH_RECT, (40, 1))
        kernel_vertical = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 40))
        
        # Detectar linhas horizontais e verticais
        horizontal_lines = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel_horizontal)
        vertical_lines = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel_vertical)
        
        # Combinar linhas para encontrar regi√µes de texto
        combined = cv2.add(horizontal_lines, vertical_lines)
        
        # Dilata√ß√£o para conectar componentes pr√≥ximos
        kernel_dilate = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))
        dilated = cv2.dilate(combined, kernel_dilate, iterations=3)
        
        # Encontrar contornos
        contours, _ = cv2.findContours(dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        # Filtrar contornos por tamanho e raz√£o de aspecto
        text_regions = []
        min_area = 500  # √Årea m√≠nima
        
        for contour in contours:
            x, y, w, h = cv2.boundingRect(contour)
            area = w * h
            
            if area > min_area and w > 50 and h > 20:
                text_regions.append((x, y, w, h))
        
        # Ordenar regi√µes por posi√ß√£o (top-to-bottom, left-to-right)
        text_regions.sort(key=lambda region: (region[1], region[0]))
        
        return text_regions
    
    except Exception as e:
        print(f"Erro na detec√ß√£o de regi√µes de texto: {e}")
        # Retornar a imagem inteira como uma √∫nica regi√£o
        h, w = image.shape[:2]
        return [(0, 0, w, h)]

def enhance_text_contrast(image: np.ndarray) -> np.ndarray:
    """
    Melhora o contraste especificamente para texto usando t√©cnicas avan√ßadas.
    """
    try:
        # Converter para escala de cinza se necess√°rio
        if len(image.shape) == 3:
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        else:
            gray = image.copy()
        
        # 1. Equaliza√ß√£o de histograma adaptativa por regi√µes
        clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))
        enhanced = clahe.apply(gray)
        
        # 2. Aplicar filtro de realce de borda suave
        kernel_sharpen = np.array([[-1, -1, -1],
                                  [-1,  9, -1],
                                  [-1, -1, -1]])
        sharpened = cv2.filter2D(enhanced, -1, kernel_sharpen)
        
        # 3. Normaliza√ß√£o gamma adaptativa
        gamma = 1.2
        gamma_corrected = np.power(sharpened / 255.0, gamma) * 255
        gamma_corrected = gamma_corrected.astype(np.uint8)
        
        # 4. Redu√ß√£o de ru√≠do preservando bordas
        denoised = cv2.bilateralFilter(gamma_corrected, 9, 80, 80)
        
        return denoised
    
    except Exception as e:
        print(f"Erro no enhancement de contraste: {e}")
        return image

def remove_artifacts(image: np.ndarray) -> np.ndarray:
    """
    Remove artefatos comuns como pontos, linhas e ru√≠dos.
    """
    try:
        # Converter para escala de cinza se necess√°rio
        if len(image.shape) == 3:
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        else:
            gray = image.copy()
        
        # 1. Remover pontos pequenos (ru√≠do salt-and-pepper)
        kernel_small = np.ones((2, 2), np.uint8)
        opened = cv2.morphologyEx(gray, cv2.MORPH_OPEN, kernel_small)
        
        # 2. Detectar e remover linhas horizontais/verticais que n√£o s√£o texto
        binary = cv2.threshold(opened, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]
        
        # Kernel para detectar linhas horizontais longas
        horizontal_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (80, 1))
        horizontal_lines = cv2.morphologyEx(binary, cv2.MORPH_OPEN, horizontal_kernel)
        
        # Kernel para detectar linhas verticais longas
        vertical_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 80))
        vertical_lines = cv2.morphologyEx(binary, cv2.MORPH_OPEN, vertical_kernel)
        
        # Combinar linhas detectadas
        lines_mask = cv2.add(horizontal_lines, vertical_lines)
        
        # Remover linhas da imagem original (inverter m√°scara)
        lines_mask_inv = cv2.bitwise_not(lines_mask)
        cleaned = cv2.bitwise_and(opened, lines_mask_inv)
        
        # 3. Aplicar fechamento para conectar letras quebradas
        kernel_close = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))
        closed = cv2.morphologyEx(cleaned, cv2.MORPH_CLOSE, kernel_close)
        
        return closed
    
    except Exception as e:
        print(f"Erro na remo√ß√£o de artefatos: {e}")
        return image

def preprocess_image(image: np.ndarray, enhancement_level: str = "medium") -> np.ndarray:
    """
    Pr√©-processa imagem com t√©cnicas avan√ßadas baseadas no n√≠vel de melhoria especificado.
    Agora inclui: detec√ß√£o de layout, corre√ß√£o de perspectiva, e realce adaptativo.
    """
    try:
        original_image = image.copy()
        
        # 1. **CORRE√á√ÉO DE PERSPECTIVA AUTOM√ÅTICA**
        print("üîÑ Aplicando corre√ß√£o de perspectiva...")
        corrected_image = auto_perspective_correction(original_image)
        
        # 2. **DETEC√á√ÉO INTELIGENTE DE LAYOUT**
        print("üîç Analisando layout do documento...")
        layout_info = intelligent_layout_detection(corrected_image)
        print(f"üìÑ Layout detectado: {layout_info['type']} ({layout_info['column_count']} colunas)")
        
        # 3. **REALCE ADAPTATIVO BASEADO NA QUALIDADE**
        print("‚ú® Aplicando realce adaptativo...")
        enhanced_image = adaptive_image_enhancement(corrected_image, enhancement_level)
        
        # 4. **PROCESSAMENTO ESPEC√çFICO POR N√çVEL**
        if enhancement_level == "conservative":
            return apply_conservative_processing(enhanced_image)
        elif enhancement_level == "medium":
            return apply_medium_processing(enhanced_image)
        elif enhancement_level == "aggressive":
            return apply_aggressive_processing(enhanced_image, layout_info)
        elif enhancement_level == "ultra":
            return apply_ultra_processing(enhanced_image, layout_info)
        else:
            return enhanced_image
            
    except Exception as e:
        print(f"‚ùå Erro no pr√©-processamento: {e}")
        return image

def apply_conservative_processing(image: np.ndarray) -> np.ndarray:
    """Processamento conservador com m√≠nima altera√ß√£o da imagem."""
    try:
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) if len(image.shape) == 3 else image
        
        # Apenas suaviza√ß√£o muito leve
        denoised = cv2.fastNlMeansDenoising(gray, h=10)
        
        # Threshold adaptativo suave
        processed = cv2.adaptiveThreshold(
            denoised, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 15, 8
        )
        
        return processed
        
    except Exception as e:
        print(f"Erro no processamento conservador: {e}")
        return image

def apply_medium_processing(image: np.ndarray) -> np.ndarray:
    """Processamento m√©dio balanceado."""
    try:
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) if len(image.shape) == 3 else image
        
        # Denoising moderado
        denoised = cv2.fastNlMeansDenoising(gray, h=15)
        
        # Equaliza√ß√£o de histograma adaptativa
        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
        enhanced = clahe.apply(denoised)
        
        # Threshold adaptativo
        processed = cv2.adaptiveThreshold(
            enhanced, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 6
        )
        
        return processed
        
    except Exception as e:
        print(f"Erro no processamento m√©dio: {e}")
        return image

def apply_aggressive_processing(image: np.ndarray, layout_info: Dict) -> np.ndarray:
    """Processamento agressivo com otimiza√ß√µes baseadas no layout."""
    try:
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) if len(image.shape) == 3 else image
        
        # Denoising mais forte
        denoised = cv2.fastNlMeansDenoising(gray, h=20)
        
        # Filtro bilateral para preservar bordas
        bilateral = cv2.bilateralFilter(denoised, 9, 75, 75)
        
        # Sharpening adaptativo
        kernel = np.array([[-1, -1, -1], [-1, 9, -1], [-1, -1, -1]])
        sharpened = cv2.filter2D(bilateral, -1, kernel)
        
        # Normaliza√ß√£o
        normalized = cv2.normalize(sharpened, None, 0, 255, cv2.NORM_MINMAX)
        
        # Threshold adaptativo otimizado para o tipo de layout
        if layout_info.get('has_tables', False):
            # Para tabelas, usar threshold mais r√≠gido
            processed = cv2.adaptiveThreshold(
                normalized, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 9, 4
            )
        else:
            # Para texto normal
            processed = cv2.adaptiveThreshold(
                normalized, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 4
            )
        
        return processed
        
    except Exception as e:
        print(f"Erro no processamento agressivo: {e}")
        return image

def apply_ultra_processing(image: np.ndarray, layout_info: Dict) -> np.ndarray:
    """
    Processamento ultra com todas as t√©cnicas avan√ßadas.
    OTIMIZADO para reduzir ru√≠do ao m√°ximo.
    """
    try:
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) if len(image.shape) == 3 else image
        
        # **1. DENOISING MULTI-EST√ÅGIO**
        # Primeiro est√°gio: denoising suave
        denoised1 = cv2.fastNlMeansDenoising(gray, h=12)
        
        # **2. CORRE√á√ÉO DE ORIENTA√á√ÉO CONSERVADORA**
        angle = detect_skew_angle(denoised1)
        if abs(angle) > 1.0:  # S√≥ corrigir se significativo
            print(f"üîÑ Corrigindo orienta√ß√£o: {angle:.2f}¬∞")
            denoised1 = rotate_image(denoised1, angle)
        
        # **3. FILTRO BILATERAL PARA PRESERVAR BORDAS**
        bilateral = cv2.bilateralFilter(denoised1, 7, 50, 50)
        
        # **4. SHARPENING MUITO SUAVE**
        kernel = np.array([[0, -0.5, 0], [-0.5, 3, -0.5], [0, -0.5, 0]])
        sharpened = cv2.filter2D(bilateral, -1, kernel)
        
        # **5. NORMALIZA√á√ÉO CUIDADOSA**
        normalized = cv2.normalize(sharpened, None, 0, 255, cv2.NORM_MINMAX)
        
        # **6. THRESHOLD ADAPTATIVO OTIMIZADO**
        processed = cv2.adaptiveThreshold(
            normalized, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 15, 8
        )
        
        # **7. LIMPEZA P√ìS-PROCESSAMENTO**
        # Remover pontos isolados pequenos
        kernel_clean = np.ones((2, 2), np.uint8)
        cleaned = cv2.morphologyEx(processed, cv2.MORPH_OPEN, kernel_clean)
        
        return cleaned
        
    except Exception as e:
        print(f"‚ùå Erro no processamento ultra: {e}")
        return image

def extract_text_with_multiple_configs(image):
    """
    Tenta extrair texto usando m√∫ltiplas configura√ß√µes do Tesseract
    e retorna o melhor resultado baseado em heur√≠sticas avan√ßadas.
    """
    
    # Configura√ß√µes otimizadas do Tesseract para diferentes tipos de documento
    configs = [
        # Configura√ß√£o principal otimizada para portugu√™s - melhor qualidade
        '--oem 3 --psm 6 -c tessedit_char_whitelist=ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz√Ä√Å√Ç√É√Ñ√Ö√Ü√á√à√â√ä√ã√å√ç√é√è√ê√ë√í√ì√î√ï√ñ√ò√ô√ö√õ√ú√ù√û√ü√†√°√¢√£√§√•√¶√ß√®√©√™√´√¨√≠√Æ√Ø√∞√±√≤√≥√¥√µ√∂√∏√π√∫√ª√º√Ω√æ√ø0123456789.,;:!?()[]{} -c tessedit_enable_dict_correction=1 -c preserve_interword_spaces=1',
        
        # Para documentos de alta qualidade com texto limpo
        '--oem 3 --psm 6 -c tessedit_enable_dict_correction=1 -c preserve_interword_spaces=1 -c textord_really_old_xheight=0',
        
        # Para documentos com layout simples
        '--oem 3 --psm 4 -c preserve_interword_spaces=1 -c tessedit_enable_dict_correction=1',
        
        # Para blocos de texto √∫nicos
        '--oem 3 --psm 6 -c preserve_interword_spaces=1 -c tessedit_enable_dict_correction=1 -c textord_heavy_nr=0',
        
        # Para documentos digitalizados com boa qualidade
        '--oem 3 --psm 3 -c tessedit_enable_dict_correction=1 -c textord_really_old_xheight=1',
        
        # Para linhas de texto individuais
        '--oem 3 --psm 7 -c tessedit_enable_dict_correction=1 -c preserve_interword_spaces=1',
        
        # Configura√ß√£o mais conservadora para textos dif√≠ceis
        '--oem 1 --psm 6 -c tessedit_enable_dict_correction=1 -c preserve_interword_spaces=1',
        
        # Para documentos com layout complexo
        '--oem 3 --psm 1 -c tessedit_enable_dict_correction=1 -c textord_heavy_nr=1',
    ]
    
    results = []
    
    for config in configs:
        try:
            # Extrair texto
            text = pytesseract.image_to_string(image, lang='por', config=config)
            
            # P√≥s-processar o texto
            text = post_process_text(text)
            
            # Extrair dados de confian√ßa
            data = pytesseract.image_to_data(image, lang='por', config=config, output_type=pytesseract.Output.DICT)
            
            # Calcular qualidade do resultado (heur√≠stica avan√ßada)
            confidence = calculate_average_confidence(data)
            quality_score = calculate_text_quality(text, confidence)
            
            results.append({
                'text': text,
                'confidence': confidence,
                'quality': quality_score,
                'config': config,
                'data': data,
                'engine': 'Tesseract'
            })
            
        except Exception as e:
            continue
    
    # Retornar o melhor resultado
    if results:
        best_result = max(results, key=lambda x: x['quality'])
        return best_result
    else:
        return {
            'text': "",
            'confidence': 0,
            'quality': 0,
            'config': "default",
            'data': {},
            'engine': 'Tesseract'
        }

def calculate_text_quality(text: str, confidence: float, layout_info: Dict = None) -> float:
    """
    Calcula a qualidade do texto extra√≠do com base em m√∫ltiplos fatores.
    Agora inclui an√°lise baseada no layout detectado.
    
    Args:
        text: Texto extra√≠do
        confidence: Confian√ßa m√©dia do OCR
        layout_info: Informa√ß√µes sobre o layout do documento
    
    Returns:
        float: Pontua√ß√£o de qualidade (0-100)
    """
    if not text or not text.strip():
        return 0
    
    try:
        score = 0
        text = text.strip()
        
        # **1. CONFIAN√áA DO OCR (Peso: 35%)**
        confidence_score = min(confidence, 100) * 0.35
        score += confidence_score
        
        # **2. AN√ÅLISE ESTRUTURAL DO TEXTO (Peso: 25%)**
        lines = [line.strip() for line in text.split('\n') if line.strip()]
        words = text.split()
        
        # Pontua√ß√£o por n√∫mero de palavras
        word_count_score = min(len(words) * 1.2, 60)  # M√°ximo 60 pontos
        score += word_count_score * 0.25
        
        # **3. QUALIDADE DOS CARACTERES (Peso: 20%)**
        # An√°lise do comprimento m√©dio das palavras
        if words:
            avg_word_length = sum(len(word) for word in words) / len(words)
            if 2 <= avg_word_length <= 12:
                char_quality_score = 20
            elif avg_word_length > 15:
                char_quality_score = 5  # Penaliza palavras muito longas (poss√≠vel ru√≠do)
            else:
                char_quality_score = 10
        else:
            char_quality_score = 0
        
        score += char_quality_score
        
        # **4. DETEC√á√ÉO DE RU√çDO (Peso: -10% a -30%)**
        # Caracteres isolados e ru√≠do
        isolated_chars = len(re.findall(r'\b[|!@#$%^&*=+~`]\b', text))
        noise_penalty = min(isolated_chars * 12, 30)  # Penalidade aumentada
        score -= noise_penalty
        
        # Sequ√™ncias repetitivas suspeitas
        repetitive_patterns = len(re.findall(r'([|!@#$%^&*=+~-])\1{1,}', text))
        repetitive_penalty = min(repetitive_patterns * 8, 20)
        score -= repetitive_penalty
        
        # **5. PALAVRAS PORTUGUESAS COMUNS (Peso: 15%)**
        portuguese_words = {
            'o', 'a', 'de', 'que', 'e', 'do', 'da', 'em', 'um', 'para', '√©', 'com', 'n√£o', 'uma', 'os', 'no', 'se', 'na', 'por', 'mais', 'as', 'dos', 'como', 'mas', 'foi', 'ao', 'ele', 'das', 'tem', '√†', 'seu', 'sua', 'ou', 'ser', 'quando', 'muito', 'h√°', 'nos', 'j√°', 'est√°', 'eu', 'tamb√©m', 's√≥', 'pelo', 'pela', 'at√©', 'isso', 'ela', 'entre', 'era', 'depois', 'sem', 'mesmo', 'aos', 'ter', 'seus', 'suas', 'numa', 'nem', 'suas', 'meu', '√†s', 'minha', 't√™m', 'numa', 'pelos', 'pelas', 's√£o', 'qual', 'ser√°', 'n√≥s', 'tenho', 'lhe', 'deles', 'essas', 'esses', 'pelas', 'este', 'onde', 'bem', 'te', 'dela', 'tu', 'antes', 'vem', 'porque', 'nada', 'dizer', 'cada', 'grande', 'estado', 'fazer', 'governo', 'ainda', 'sobre', 'nacional', 'trabalho', 'caso', 'grupo', 'durante', 'p√∫blico', 'primeiro', 'tempo', 'ano', 'anos', 'acordo', 'geral', 'parte', 'lugar', 'vida', 'dia', 'forma', '√°rea', 'momento', 'desenvolvimento', 'processo', 'sistema', 'pol√≠tica', 'empresa', 'pessoa', 'programa', 'problema', 'projeto', 'servi√ßo', 'mercado', 'recursos', 'social', 'informa√ß√£o', 'dados', 'valor'
        }
        
        word_matches = 0
        valid_words = [word.lower().strip('.,;:!?()[]{}"\'-') for word in words if len(word) > 2]
        
        for word in valid_words:
            if word in portuguese_words:
                word_matches += 1
        
        if valid_words:
            portuguese_ratio = word_matches / len(valid_words)
            portuguese_score = min(portuguese_ratio * 45, 45)  # Aumentado para 45
        else:
            portuguese_score = 0
        
        score += portuguese_score
        
        # **6. AN√ÅLISE DE LAYOUT ESPEC√çFICO (Peso: 10%)**
        layout_score = 0
        if layout_info:
            # Bonus para textos que respeitam o layout detectado
            if layout_info.get('type') == 'table_mixed' and '|' in text:
                layout_score += 8  # Bonus para texto que parece tabela
            elif layout_info.get('column_count', 1) > 1:
                # Para m√∫ltiplas colunas, verificar se o texto tem estrutura adequada
                if len(lines) > 5:  # Textos com m√∫ltiplas linhas s√£o esperados
                    layout_score += 6
            elif layout_info.get('type') == 'single_column':
                # Para coluna √∫nica, premiar textos coesos
                if len(lines) > 0 and all(len(line.split()) > 2 for line in lines[:5]):
                    layout_score += 7
            
            # Bonus para textos com cabe√ßalhos detectados apropriadamente
            if layout_info.get('header_regions') and any(line.isupper() or line.istitle() for line in lines[:3]):
                layout_score += 5
        
        score += layout_score
        
        # **7. PROPOR√á√ÉO DE LETRAS (Peso: 10%)**
        if text:
            letter_count = sum(1 for c in text if c.isalpha())
            total_chars = len(text.replace(' ', '').replace('\n', ''))
            
            if total_chars > 0:
                letter_ratio = letter_count / total_chars
                if letter_ratio >= 0.7:  # Ideal: pelo menos 70% letras
                    ratio_score = 15
                elif letter_ratio >= 0.5:
                    ratio_score = 10
                elif letter_ratio >= 0.3:
                    ratio_score = 5
                else:
                    ratio_score = 0
                    score -= 25  # Penalidade forte para textos com poucas letras
            else:
                ratio_score = 0
        else:
            ratio_score = 0
        
        score += ratio_score
        
        # **8. FORMATA√á√ÉO E ESTRUTURA (Peso: 5%)**
        # Mai√∫sculas no in√≠cio de frases
        sentences = re.split(r'[.!?]+', text)
        proper_caps = sum(1 for s in sentences if s.strip() and s.strip()[0].isupper())
        caps_score = min(proper_caps * 3, 10)
        
        # Par√°grafos bem formados
        paragraphs = text.split('\n\n')
        paragraph_score = min(len(paragraphs) * 2, 6)
        
        formatting_score = caps_score + paragraph_score
        score += formatting_score
        
        # **9. PENALIZA√á√ÉO POR LINHAS MUITO CURTAS**
        if lines:
            short_lines = sum(1 for line in lines if len(line.split()) <= 2)
            if short_lines / len(lines) > 0.6:  # Mais de 60% das linhas s√£o muito curtas
                score -= 15
        
        # **10. LIMITAR SCORE ENTRE 0 E 100**
        final_score = max(0, min(100, score))
        
        return final_score
        
    except Exception as e:
        print(f"Erro no c√°lculo de qualidade: {e}")
        return 0

def post_process_text(text: str) -> str:
    """
    Aplica p√≥s-processamento ao texto extra√≠do para corrigir erros comuns.
    """
    if not text:
        return text
    
    processed_text = text
    
    # 1. Remover caracteres isolados suspeitos (muito comuns em OCR com ru√≠do)
    # Remover caracteres √∫nicos que n√£o fazem sentido
    processed_text = re.sub(r'\b[|!@#$%^&*=+~`<>{}[\]\\]+\b', ' ', processed_text)
    
    # 2. Corrigir sequ√™ncias de caracteres especiais repetitivos
    processed_text = re.sub(r'[|_\-=]{3,}', ' ', processed_text)  # M√∫ltiplos tra√ßos
    processed_text = re.sub(r'[.]{3,}', '...', processed_text)  # M√∫ltiplos pontos
    
    # 3. Corre√ß√µes de caracteres comuns mal interpretados
    corrections = {
        # OCR confusions comuns em contexto
        '‚Äî': '-',
        '‚Äì': '-',
        '"': '"',
        '"': '"',
        ''': "'",
        ''': "'",
        '‚Ä¶': '...',
        '¬∞': 'o',  # Grau vs o min√∫sculo
        '¬®': '"',  # Trema vs aspas
        '¬¥': "'",  # Acento vs ap√≥strofe
    }
    
    # Aplicar corre√ß√µes b√°sicas
    for wrong, correct in corrections.items():
        processed_text = processed_text.replace(wrong, correct)
    
    # 4. Corre√ß√µes contextuais mais inteligentes
    # Corrigir n√∫meros mal interpretados apenas em contexto de palavras
    processed_text = re.sub(r'\b0(?=[a-zA-Z√Ä-√ø])', 'O', processed_text)  # 0 seguido de letra -> O
    processed_text = re.sub(r'(?<=[a-zA-Z√Ä-√ø])0\b', 'o', processed_text)  # 0 precedido de letra -> o
    processed_text = re.sub(r'\b1(?=[a-zA-Z√Ä-√ø])', 'I', processed_text)  # 1 seguido de letra -> I
    processed_text = re.sub(r'(?<=[a-zA-Z√Ä-√ø])1(?=[a-zA-Z√Ä-√ø])', 'l', processed_text)  # 1 entre letras -> l
    
    # 5. Corrigir letras mal interpretadas como n√∫meros em contexto
    processed_text = re.sub(r'(?<=[a-zA-Z√Ä-√ø])5(?=[a-zA-Z√Ä-√ø])', 'S', processed_text)  # 5 entre letras -> S
    processed_text = re.sub(r'(?<=[a-zA-Z√Ä-√ø])8(?=[a-zA-Z√Ä-√ø])', 'B', processed_text)  # 8 entre letras -> B
    
    # 6. Remover linhas que s√£o principalmente ru√≠do
    lines = processed_text.split('\n')
    cleaned_lines = []
    
    for line in lines:
        line = line.strip()
        if len(line) == 0:
            continue
            
        # Calcular propor√ß√£o de caracteres alfab√©ticos
        alpha_chars = sum(1 for c in line if c.isalpha())
        total_chars = len(line)
        
        # Manter linha se tiver propor√ß√£o razo√°vel de letras ou for muito curta
        if total_chars <= 3 or (total_chars > 0 and alpha_chars / total_chars >= 0.3):
            # Remover caracteres isolados suspeitos no in√≠cio/fim da linha
            line = re.sub(r'^[^\w\s]+|[^\w\s]+$', '', line).strip()
            if line:
                cleaned_lines.append(line)
    
    processed_text = '\n'.join(cleaned_lines)
    
    # 7. Limpar espa√ßamentos m√∫ltiplos
    processed_text = re.sub(r' +', ' ', processed_text)
    
    # 8. Corrigir quebras de linha problem√°ticas
    # Remover quebras de linha no meio de palavras (hifeniza√ß√£o)
    processed_text = re.sub(r'(\w)-\n(\w)', r'\1\2', processed_text)
    
    # 9. Normalizar pontua√ß√£o
    processed_text = re.sub(r'\s+([,.;:!?])', r'\1', processed_text)  # Remove espa√ßo antes de pontua√ß√£o
    processed_text = re.sub(r'([,.;:!?])(?![,.\s])', r'\1 ', processed_text)  # Adiciona espa√ßo ap√≥s pontua√ß√£o
    
    # 10. Remover linhas muito curtas que s√£o provavelmente ru√≠do
    lines = processed_text.split('\n')
    final_lines = []
    
    for line in lines:
        line = line.strip()
        # Manter apenas linhas com pelo menos 2 caracteres ou que sejam n√∫meros
        if len(line) >= 2 or (len(line) == 1 and line.isdigit()):
            final_lines.append(line)
    
    return '\n'.join(final_lines).strip()

def cleanup_temp_file(file_path: str):
    """
    Fun√ß√£o s√≠ncrona para deletar arquivo tempor√°rio ap√≥s enviar resposta
    """
    try:
        if os.path.exists(file_path):
            os.remove(file_path)
            print(f"Arquivo tempor√°rio removido: {file_path}")
    except Exception as e:
        print(f"Erro ao remover arquivo tempor√°rio {file_path}: {e}")

@app.get("/")
async def read_root():
    return {"message": "API de OCR para PDFs - Envie um PDF n√£o pesquis√°vel e receba um PDF pesquis√°vel!"}

@app.post("/convert-pdf/")
async def convert_pdf_to_searchable(
    file: UploadFile = File(...), 
    background_tasks: BackgroundTasks = BackgroundTasks(),
    enhancement_level: str = "medium",
    resolution_scale: float = 2.0
):
    """
    Converte um PDF n√£o pesquis√°vel (com imagens) em um PDF pesquis√°vel usando OCR.
    
    Args:
        file: Arquivo PDF para convers√£o
        enhancement_level: "basic", "medium", "aggressive", "ultra" - N√≠vel de pr√©-processamento
        resolution_scale: Fator de escala para resolu√ß√£o (1.0-4.0, padr√£o 2.0)
    """
    
    # Validar tipo do arquivo
    if not file.filename.lower().endswith('.pdf'):
        raise HTTPException(status_code=400, detail="Arquivo deve ser um PDF")
    
    # Validar par√¢metros
    if enhancement_level not in ["basic", "medium", "aggressive", "ultra"]:
        raise HTTPException(status_code=400, detail="enhancement_level deve ser 'basic', 'medium', 'aggressive' ou 'ultra'")
    
    if not 1.0 <= resolution_scale <= 4.0:
        raise HTTPException(status_code=400, detail="resolution_scale deve estar entre 1.0 e 4.0")
    
    try:
        # Ler o arquivo PDF
        pdf_content = await file.read()
        pdf_document = fitz.open(stream=pdf_content, filetype="pdf")
        
        # Criar um novo PDF para armazenar o resultado
        output_pdf = fitz.open()
        
        # Processar cada p√°gina
        for page_num in range(pdf_document.page_count):
            page = pdf_document[page_num]
            
            # Converter p√°gina para imagem com resolu√ß√£o ajustada
            pix = page.get_pixmap(matrix=fitz.Matrix(resolution_scale, resolution_scale))
            img_data = pix.tobytes("png")
            
            # Converter para PIL Image
            image = Image.open(io.BytesIO(img_data))
            
            # Aplicar pr√©-processamento
            processed_image = preprocess_image(image, enhancement_level)
            
            # Extrair texto usando OCR
            result = extract_text_with_multiple_configs(processed_image)
            texto_ocr = result['text']
            config = result['config']
            ocr_data = result['data']
            
            # Criar nova p√°gina no PDF de sa√≠da
            nova_pagina = output_pdf.new_page(width=page.rect.width, height=page.rect.height)
            
            # Inserir a imagem original como fundo
            nova_pagina.insert_image(nova_pagina.rect, stream=img_data)
            
            # Adicionar texto invis√≠vel para permitir pesquisa
            if texto_ocr.strip():
                # Inserir texto invis√≠vel sobre a imagem
                # O texto ser√° invis√≠vel mas pesquis√°vel
                text_rect = fitz.Rect(0, 0, page.rect.width, page.rect.height)
                nova_pagina.insert_textbox(
                    text_rect,
                    texto_ocr,
                    fontsize=8,
                    color=(1, 1, 1),  # Texto branco (invis√≠vel)
                    overlay=False
                )
        
        # Salvar PDF convertido em arquivo tempor√°rio
        temp_id = str(uuid.uuid4())
        output_path = os.path.join("temp", f"output_{temp_id}.pdf")
        output_pdf.save(output_path)
        
        # Fechar documentos
        pdf_document.close()
        output_pdf.close()
        
        # Adicionar tarefa em background para limpar arquivo tempor√°rio
        background_tasks.add_task(cleanup_temp_file, output_path)
        
        # Retornar o arquivo convertido
        return FileResponse(
            path=output_path,
            filename=f"ocr_{enhancement_level}_{file.filename}",
            media_type="application/pdf"
        )
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Erro ao processar PDF: {str(e)}")

@app.post("/extract-text/")
async def extract_text_from_pdf(
    file: UploadFile = File(...),
    enhancement_level: str = "medium",
    resolution_scale: float = 2.0
):
    """
    Extrai apenas o texto de um PDF n√£o pesquis√°vel usando OCR.
    
    Args:
        file: Arquivo PDF para extra√ß√£o
        enhancement_level: "basic", "medium", "aggressive", "ultra" - N√≠vel de pr√©-processamento
        resolution_scale: Fator de escala para resolu√ß√£o (1.0-4.0, padr√£o 2.0)
    """
    
    # Validar tipo do arquivo
    if not file.filename.lower().endswith('.pdf'):
        raise HTTPException(status_code=400, detail="Arquivo deve ser um PDF")
    
    # Validar par√¢metros
    if enhancement_level not in ["basic", "medium", "aggressive", "ultra"]:
        raise HTTPException(status_code=400, detail="enhancement_level deve ser 'basic', 'medium', 'aggressive' ou 'ultra'")
    
    if not 1.0 <= resolution_scale <= 4.0:
        raise HTTPException(status_code=400, detail="resolution_scale deve estar entre 1.0 e 4.0")
    
    try:
        # Ler o arquivo PDF
        pdf_content = await file.read()
        pdf_document = fitz.open(stream=pdf_content, filetype="pdf")
        
        extracted_text = []
        
        # Processar cada p√°gina
        for page_num in range(pdf_document.page_count):
            page = pdf_document[page_num]
            
            # Converter p√°gina para imagem com resolu√ß√£o ajustada
            pix = page.get_pixmap(matrix=fitz.Matrix(resolution_scale, resolution_scale))
            img_data = pix.tobytes("png")
            
            # Converter para PIL Image
            image = Image.open(io.BytesIO(img_data))
            
            # Aplicar pr√©-processamento
            processed_image = preprocess_image(image, enhancement_level)
            
            # Extrair texto usando OCR
            result = extract_text_with_multiple_configs(processed_image)
            texto_ocr = result['text']
            config = result['config']
            ocr_data = result['data']
            
            extracted_text.append({
                "pagina": page_num + 1,
                "texto": texto_ocr.strip(),
                "configuracao": config,
                "parametros": {
                    "enhancement_level": enhancement_level,
                    "resolution_scale": resolution_scale
                }
            })
        
        pdf_document.close()
        
        return {
            "filename": file.filename,
            "total_paginas": len(extracted_text),
            "texto_extraido": extracted_text,
            "configuracao_global": {
                "enhancement_level": enhancement_level,
                "resolution_scale": resolution_scale
            }
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Erro ao extrair texto: {str(e)}")

@app.post("/extract-text-progress/")
async def extract_text_with_progress(
    file: UploadFile = File(...),
    enhancement_level: str = "medium",
    resolution_scale: float = 2.0
):
    """
    Extrai texto de PDF com indicador de progresso em tempo real usando Server-Sent Events.
    
    Args:
        file: Arquivo PDF para extra√ß√£o
        enhancement_level: "basic", "medium", "aggressive", "ultra" - N√≠vel de pr√©-processamento
        resolution_scale: Fator de escala para resolu√ß√£o (1.0-4.0, padr√£o 2.0)
    """
    
    # Validar tipo do arquivo
    if not file.filename.lower().endswith('.pdf'):
        raise HTTPException(status_code=400, detail="Arquivo deve ser um PDF")
    
    # Validar par√¢metros
    if enhancement_level not in ["basic", "medium", "aggressive", "ultra"]:
        raise HTTPException(status_code=400, detail="enhancement_level deve ser 'basic', 'medium', 'aggressive' ou 'ultra'")
    
    if not 1.0 <= resolution_scale <= 4.0:
        raise HTTPException(status_code=400, detail="resolution_scale deve estar entre 1.0 e 4.0")
    
    async def generate_progress():
        try:
            # Ler o arquivo PDF
            pdf_content = await file.read()
            pdf_document = fitz.open(stream=pdf_content, filetype="pdf")
            total_pages = pdf_document.page_count
            
            # Enviar informa√ß√µes iniciais
            initial_data = {
                "tipo": "info",
                "timestamp": str(asyncio.get_event_loop().time()),
                "arquivo": {
                    "nome": file.filename,
                    "tamanho_mb": round(len(pdf_content) / (1024 * 1024), 2)
                },
                "processamento": {
                    "total_paginas": total_pages,
                    "progresso_atual": 0,
                    "status": "Iniciando processamento"
                }
            }
            yield f"data: {json.dumps(initial_data, ensure_ascii=False)}\n\n"
            
            all_text = []
            start_time = time.time()
            
            # Processar cada p√°gina
            for page_num in range(total_pages):
                # Calcular progresso
                progress_percent = int((page_num / total_pages) * 100)
                
                # Enviar progresso atual
                progress_data = {
                    "tipo": "progresso",
                    "timestamp": str(asyncio.get_event_loop().time()),
                    "processamento": {
                        "pagina_atual": page_num + 1,
                        "total_paginas": total_pages,
                        "progresso_percent": progress_percent,
                        "status": f"Processando p√°gina {page_num + 1} de {total_pages}",
                        "etapa": "ocr_em_andamento"
                    },
                    "estatisticas": {
                        "paginas_concluidas": page_num,
                        "caracteres_extraidos": 0,
                        "tempo_decorrido": round(asyncio.get_event_loop().time(), 2)
                    }
                }
                yield f"data: {json.dumps(progress_data, ensure_ascii=False)}\n\n"
                
                page = pdf_document[page_num]
                
                # Converter p√°gina para imagem com resolu√ß√£o ajustada
                pix = page.get_pixmap(matrix=fitz.Matrix(resolution_scale, resolution_scale))
                img_data = pix.tobytes("png")
                
                # Converter para PIL Image
                image = Image.open(io.BytesIO(img_data))
                
                # Aplicar pr√©-processamento
                processed_image = preprocess_image(image, enhancement_level)
                
                # Extrair texto usando OCR
                result = extract_text_with_multiple_configs(processed_image)
                texto_ocr = result['text']
                config = result['config']
                ocr_data = result['data']
                
                # Enviar informa√ß√µes da p√°gina processada
                page_info = {
                    "tipo": "pagina_concluida",
                    "timestamp": datetime.now().isoformat(),
                    "arquivo": {
                        "nome": file.filename,
                        "pagina_atual": page_num + 1,
                        "total_paginas": total_pages
                    },
                    "processamento": {
                        "porcentagem": int((page_num + 1) / total_pages * 100),
                        "tempo_decorrido": f"{time.time() - start_time:.2f}s",
                        "configuracao_ocr": config,
                        "parametros": {
                            "enhancement_level": enhancement_level,
                            "resolution_scale": resolution_scale
                        }
                    },
                    "resultados": {
                        "pagina": page_num + 1,
                        "texto": texto_ocr.strip(),
                        "estatisticas": {
                            "caracteres": len(texto_ocr.strip()),
                            "linhas": len(texto_ocr.strip().split('\n')) if texto_ocr.strip() else 0,
                            "palavras": len(texto_ocr.strip().split()) if texto_ocr.strip() else 0
                        }
                    }
                }
                
                all_text.append(page_info["resultados"])
                yield f"data: {json.dumps(page_info, ensure_ascii=False)}\n\n"
                
            # Calcular estat√≠sticas finais
            total_characters = sum(page["estatisticas"]["caracteres"] for page in all_text)
            total_words = sum(page["estatisticas"]["palavras"] for page in all_text)
            total_lines = sum(page["estatisticas"]["linhas"] for page in all_text)
            
            # Encontrar p√°gina com mais e menos texto
            pages_with_text = [page for page in all_text if page["estatisticas"]["caracteres"] > 0]
            longest_page = max(pages_with_text, key=lambda x: x["estatisticas"]["caracteres"]) if pages_with_text else None
            shortest_page = min(pages_with_text, key=lambda x: x["estatisticas"]["caracteres"]) if pages_with_text else None
            
            # Enviar resultado final
            final_result = {
                "tipo": "concluido",
                "timestamp": datetime.now().isoformat(),
                "arquivo": {
                    "nome": file.filename,
                    "total_paginas": total_pages,
                    "tempo_total": f"{time.time() - start_time:.2f}s"
                },
                "processamento": {
                    "porcentagem": 100,
                    "configuracao_global": {
                        "enhancement_level": enhancement_level,
                        "resolution_scale": resolution_scale
                    },
                    "sucesso": True
                },
                "estatisticas": {
                    "resumo": {
                        "total_caracteres": total_characters,
                        "total_palavras": total_words,
                        "total_linhas": total_lines,
                        "paginas_com_texto": len(pages_with_text),
                        "paginas_vazias": total_pages - len(pages_with_text)
                    },
                    "pagina_mais_longa": longest_page,
                    "pagina_mais_curta": shortest_page
                },
                "resultados": {
                    "texto_completo": "\n\n".join([page["texto"] for page in all_text if page["texto"]]),
                    "paginas": all_text
                }
            }
            
            yield f"data: {json.dumps(final_result, ensure_ascii=False)}\n\n"
            
        except Exception as e:
            error_result = {
                "tipo": "erro",
                "timestamp": datetime.now().isoformat(),
                "erro": {
                    "message": str(e),
                    "type": type(e).__name__
                },
                "processamento": {
                    "porcentagem": 0,
                    "sucesso": False
                }
            }
            yield f"data: {json.dumps(error_result, ensure_ascii=False)}\n\n"
    
    return StreamingResponse(
        generate_progress(),
        media_type="text/plain",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "Content-Type": "text/event-stream",
            "Access-Control-Allow-Origin": "*"
        }
    )

@app.get("/health")
async def health_check():
    """
    Endpoint para verificar se a API est√° funcionando
    """
    global engines_loading
    
    # Se engines est√£o carregando, ainda considerar saud√°vel
    if engines_loading:
        return {
            "status": "OK", 
            "message": "API funcionando - engines de IA carregando em background",
            "timestamp": datetime.datetime.now().isoformat()
        }
    
    return {
        "status": "OK", 
        "message": "API funcionando corretamente",
        "timestamp": datetime.datetime.now().isoformat()
    }

@app.get("/exemplo_progress.html")
async def get_example_page():
    """
    Serve a p√°gina de exemplo para teste do endpoint de progresso.
    """
    return FileResponse("exemplo_progress.html", media_type="text/html")

def extract_text_with_ai_engines(image):
    """
    Extrai texto usando m√∫ltiplos engines de IA com an√°lise de consenso.
    """
    print("\nüöÄ INICIANDO EXTRA√á√ÉO COM M√öLTIPLOS ENGINES DE IA")
    
    results = []
    layout_info = intelligent_layout_detection(image)
    
    print(f"üìä Layout detectado: {layout_info}")
    
    # Engine 1: Tesseract com m√∫ltiplas configura√ß√µes
    print("\nüîç ENGINE 1: TESSERACT")
    try:
        tesseract_result = extract_text_with_multiple_configs(image)
        if tesseract_result and tesseract_result.get('text', '').strip():
            results.append({
                'text': tesseract_result['text'],
                'confidence': tesseract_result['confidence'],
                'engine': 'Tesseract',
                'method': tesseract_result.get('method', 'multi_config')
            })
            print(f"‚úÖ Tesseract - Confian√ßa: {tesseract_result['confidence']:.1f}%")
            print(f"üìù Texto extra√≠do (primeiros 200 chars): {tesseract_result['text'][:200]}...")
        else:
            print("‚ùå Tesseract - Falhou na extra√ß√£o")
    except Exception as e:
        print(f"‚ùå Tesseract - Erro: {e}")
    
    # Engine 2: EasyOCR
    print("\nüîç ENGINE 2: EASYOCR")
    try:
        easyocr_results = easyocr_reader.readtext(image)
        if easyocr_results:
            easyocr_text = ' '.join([result[1] for result in easyocr_results])
            easyocr_confidence = sum([result[2] for result in easyocr_results]) / len(easyocr_results) * 100
            results.append({
                'text': easyocr_text,
                'confidence': easyocr_confidence,
                'engine': 'EasyOCR',
                'method': 'neural_network'
            })
            print(f"‚úÖ EasyOCR - Confian√ßa: {easyocr_confidence:.1f}%")
            print(f"üìù Texto extra√≠do (primeiros 200 chars): {easyocr_text[:200]}...")
        else:
            print("‚ùå EasyOCR - Nenhum texto detectado")
    except Exception as e:
        print(f"‚ùå EasyOCR - Erro: {e}")
    
    # Engine 3: TrOCR (Transformer OCR)
    try:
        print("\nüîç ENGINE 3: TrOCR")
        from PIL import Image as PILImage
        
        # Converter para PIL Image adequadamente
        if isinstance(image, np.ndarray):
            # Se √© numpy array, converter para PIL
            if image.dtype != np.uint8:
                image = (image * 255).astype(np.uint8)
            pil_image = PILImage.fromarray(image)
        elif hasattr(image, 'convert'):  # J√° √© PIL Image
            pil_image = image
        else:
            # Tentar converter de qualquer outro tipo
            pil_image = PILImage.fromarray(np.array(image))
        
        # Garantir que est√° em RGB
        if pil_image.mode != 'RGB':
            pil_image = pil_image.convert('RGB')
        
        pixel_values = trocr_processor(pil_image, return_tensors="pt").pixel_values
        generated_ids = trocr_model.generate(pixel_values)
        trocr_text = trocr_processor.batch_decode(generated_ids, skip_special_tokens=True)[0]
        
        if trocr_text.strip():
            # TrOCR n√£o fornece confian√ßa direta, estimamos baseado no tamanho e qualidade
            trocr_confidence = min(95.0, len(trocr_text.strip()) * 2.5)
            results.append({
                'text': trocr_text,
                'confidence': trocr_confidence,
                'engine': 'TrOCR',
                'method': 'transformer'
            })
            print(f"‚úÖ TrOCR - Confian√ßa estimada: {trocr_confidence:.1f}%")
            print(f"üìù Texto extra√≠do (primeiros 200 chars): {trocr_text[:200]}...")
        else:
            print("‚ùå TrOCR - Nenhum texto detectado")
    except Exception as e:
        print(f"‚ùå TrOCR - Erro: {e}")
    
    # An√°lise de consenso
    print(f"\nüìä AN√ÅLISE DE CONSENSO - {len(results)} engines executados com sucesso")
    
    if not results:
        print("‚ùå Nenhum engine conseguiu extrair texto")
        return {
            'text': '',
            'confidence': 0.0,
            'engine': 'none',
            'method': 'failed'
        }
    
    print("\nüèÜ INICIANDO AN√ÅLISE AVAN√áADA DE CONSENSO...")
    consensus_result = analyze_consensus_advanced(results, layout_info)
    
    if consensus_result:
        print(f"\nüéØ RESULTADO FINAL DO CONSENSO:")
        print(f"üèÖ Melhor engine: {consensus_result.get('engine', 'unknown')}")
        print(f"üìä Score de consenso: {consensus_result.get('consensus_score', 0):.2f}")
        print(f"üéØ Confian√ßa final: {consensus_result.get('confidence', 0):.1f}%")
        print(f"üìù Texto final (primeiros 300 chars): {consensus_result.get('text', '')[:300]}...")
        
        return {
            'text': consensus_result['text'],
            'confidence': consensus_result['confidence'],
            'engine': consensus_result.get('engine', 'consensus'),
            'method': consensus_result.get('method', 'advanced_analysis')
        }
    else:
        print("‚ùå An√°lise de consenso falhou, usando melhor resultado individual")
        best_result = max(results, key=lambda x: x['confidence'])
        return {
            'text': best_result['text'],
            'confidence': best_result['confidence'],
            'engine': best_result['engine'],
            'method': best_result.get('method', 'fallback')
        }

def analyze_consensus_advanced(results: List[Dict], layout_info: Dict) -> Dict:
    """
    An√°lise avan√ßada de consenso entre m√∫ltiplos engines de OCR.
    Considera qualidade, confian√ßa, similaridade e contexto do layout.
    """
    try:
        if not results:
            return {'text': '', 'confidence': 0, 'engine': 'none'}
        
        if len(results) == 1:
            return results[0]
        
        print(f"üîç Analisando consenso entre {len(results)} resultados...")
        
        # **1. AN√ÅLISE DE SIMILARIDADE ENTRE TEXTOS**
        similarity_matrix = []
        for i, result1 in enumerate(results):
            similarities = []
            for j, result2 in enumerate(results):
                if i != j:
                    sim = calculate_text_similarity_advanced(result1['text'], result2['text'])
                    similarities.append(sim)
                else:
                    similarities.append(1.0)
            similarity_matrix.append(similarities)
        
        # **2. PONTUA√á√ÉO PONDERADA PARA CADA RESULTADO**
        scored_results = []
        
        for i, result in enumerate(results):
            score = 0
            
            # Peso base da qualidade do texto (40%)
            quality_score = result.get('quality', 0) * 0.4
            score += quality_score
            
            # Peso da confian√ßa do engine (30%)
            confidence_score = result.get('confidence', 0) * 0.3
            score += confidence_score
            
            # Peso do consenso com outros engines (20%)
            avg_similarity = sum(similarity_matrix[i]) / len(similarity_matrix[i])
            consensus_score = avg_similarity * 20
            score += consensus_score
            
            # Bonus baseado no tipo de engine (10%)
            engine_bonus = 0
            if 'Tesseract' in result.get('engine', ''):
                engine_bonus = 8  # Tesseract √© confi√°vel para portugu√™s
            elif 'TrOCR' in result.get('engine', ''):
                engine_bonus = 10  # Transformers s√£o muito bons
            elif 'EasyOCR' in result.get('engine', ''):
                engine_bonus = 9  # Neural networks s√£o eficazes
            
            score += engine_bonus
            
            # Bonus baseado no layout (ajuste fino)
            layout_bonus = 0
            if layout_info.get('has_tables', False) and 'psm 4' in result.get('engine', ''):
                layout_bonus = 5  # Bonus para PSM 4 em tabelas
            elif layout_info.get('column_count', 1) > 1 and 'psm 3' in result.get('engine', ''):
                layout_bonus = 5  # Bonus para PSM 3 em m√∫ltiplas colunas
            
            score += layout_bonus
            
            # Penaliza√ß√£o por texto muito curto ou muito longo
            text_length = len(result['text'].strip())
            if text_length < 10:
                score -= 10  # Penaliza textos muito curtos
            elif text_length > 10000:
                score -= 5   # Penaliza textos excessivamente longos
            
            scored_results.append({
                **result,
                'consensus_score': score,
                'avg_similarity': avg_similarity,
                'breakdown': {
                    'quality': quality_score,
                    'confidence': confidence_score,
                    'consensus': consensus_score,
                    'engine_bonus': engine_bonus,
                    'layout_bonus': layout_bonus
                }
            })
        
        # **3. ORDENAR POR PONTUA√á√ÉO E SELECIONAR O MELHOR**
        scored_results.sort(key=lambda x: x['consensus_score'], reverse=True)
        
        best_result = scored_results[0]
        
        print(f"üèÜ Melhor resultado: {best_result['engine']} (Score: {best_result['consensus_score']:.1f})")
        print(f"üìä Breakdown: Q={best_result['breakdown']['quality']:.1f} | C={best_result['breakdown']['confidence']:.1f} | S={best_result['breakdown']['consensus']:.1f}")
        
        # **4. VERIFICA√á√ÉO DE QUALIDADE M√çNIMA**
        if best_result['consensus_score'] < 30:  # Threshold m√≠nimo
            print("‚ö†Ô∏è Todos os resultados t√™m qualidade baixa, aplicando fallback...")
            
            # Tentar combinar os melhores elementos
            combined_text = ""
            for result in scored_results[:2]:  # Pegar os 2 melhores
                if len(result['text'].strip()) > len(combined_text.strip()):
                    combined_text = result['text']
            
            return {
                'text': combined_text,
                'confidence': max(r['confidence'] for r in results),
                'engine': 'consensus_fallback',
                'method': 'emergency_consensus'
            }
        
        # **5. APRIMORAMENTO DO MELHOR RESULTADO**
        enhanced_text = enhance_consensus_result(best_result['text'], scored_results)
        
        return {
            'text': enhanced_text,
            'confidence': best_result['confidence'],
            'engine': best_result['engine'],
            'method': 'advanced_consensus',
            'score': best_result['consensus_score']
        }
        
    except Exception as e:
        print(f"‚ùå Erro na an√°lise de consenso: {e}")
        # Fallback: retornar o resultado com maior confian√ßa
        return max(results, key=lambda x: x.get('confidence', 0))

def calculate_text_similarity_advanced(text1: str, text2: str) -> float:
    """
    Calcula similaridade avan√ßada entre dois textos usando m√∫ltiplas m√©tricas.
    """
    try:
        if not text1.strip() or not text2.strip():
            return 0.0
        
        # Normalizar textos
        t1 = text1.lower().strip()
        t2 = text2.lower().strip()
        
        # **1. SIMILARIDADE DE CARACTERES (Jaccard)**
        set1 = set(t1)
        set2 = set(t2)
        intersection = len(set1.intersection(set2))
        union = len(set1.union(set2))
        char_similarity = intersection / union if union > 0 else 0
        
        # **2. SIMILARIDADE DE PALAVRAS**
        words1 = set(t1.split())
        words2 = set(t2.split())
        word_intersection = len(words1.intersection(words2))
        word_union = len(words1.union(words2))
        word_similarity = word_intersection / word_union if word_union > 0 else 0
        
        # **3. SIMILARIDADE DE SEQU√äNCIA (RATIO)**
        sequence_similarity = SequenceMatcher(None, t1, t2).ratio()
        
        # **4. SIMILARIDADE DE COMPRIMENTO**
        len1, len2 = len(t1), len(t2)
        length_similarity = min(len1, len2) / max(len1, len2) if max(len1, len2) > 0 else 0
        
        # **5. COMBINA√á√ÉO PONDERADA**
        final_similarity = (
            char_similarity * 0.2 +
            word_similarity * 0.4 +
            sequence_similarity * 0.3 +
            length_similarity * 0.1
        )
        
        return final_similarity
        
    except Exception as e:
        print(f"Erro no c√°lculo de similaridade: {e}")
        return 0.0

def enhance_consensus_result(best_text: str, all_results: List[Dict]) -> str:
    """
    Aprimora o melhor resultado usando informa√ß√µes dos outros engines.
    """
    try:
        if len(all_results) <= 1:
            return best_text
        
        # Coletar palavras de alta confian√ßa de todos os resultados
        high_confidence_words = set()
        
        for result in all_results:
            words = result['text'].split()
            # Adicionar palavras de engines com alta confian√ßa
            if result.get('confidence', 0) > 70:
                high_confidence_words.update(words)
        
        # Verificar se podemos melhorar o texto principal
        enhanced_text = best_text
        
        # Verifica√ß√£o b√°sica de integridade
        if len(enhanced_text.strip()) < 10:
            # Se o melhor resultado √© muito curto, tentar o segundo melhor
            for result in all_results[1:]:
                if len(result['text'].strip()) > len(enhanced_text.strip()):
                    enhanced_text = result['text']
                    break
        
        return enhanced_text
        
    except Exception as e:
        print(f"Erro no aprimoramento do resultado: {e}")
        return best_text

def analyze_consensus(results):
    """
    Analisa consenso entre diferentes motores de OCR para melhorar precis√£o.
    """
    if len(results) < 2:
        return None
    
    # Extrair textos e normalizar
    texts = [result['text'].lower().strip() for result in results]
    
    # Calcular similaridade entre textos
    similarities = []
    for i in range(len(texts)):
        for j in range(i + 1, len(texts)):
            similarity = calculate_text_similarity(texts[i], texts[j])
            similarities.append(similarity)
    
    avg_similarity = sum(similarities) / len(similarities) if similarities else 0
    
    # Se h√° alto consenso (similaridade > 0.7), combinar resultados
    if avg_similarity > 0.7:
        # Usar o resultado com maior qualidade, mas considerar consenso
        best_result = results[0].copy()
        best_result['consensus_score'] = avg_similarity
        best_result['engine'] = f"consensus_{best_result['engine']}"
        return best_result
    
    # Se baixo consenso, usar vota√ß√£o ponderada por confian√ßa
    elif len(results) >= 3:
        weighted_texts = []
        for result in results:
            weight = result['confidence'] * result['quality'] / 100
            weighted_texts.append((result['text'], weight, result))
        
        # Escolher texto com maior peso combinado
        best_weighted = max(weighted_texts, key=lambda x: x[1])
        final_result = best_weighted[2].copy()
        final_result['engine'] = f"weighted_{final_result['engine']}"
        return final_result
    
    return None

def calculate_text_similarity(text1, text2):
    """
    Calcula similaridade entre dois textos usando m√∫ltiplas m√©tricas.
    """
    if not text1 or not text2:
        return 0
    
    # 1. Similaridade de palavras (Jaccard)
    words1 = set(text1.split())
    words2 = set(text2.split())
    
    if not words1 and not words2:
        return 1.0
    
    intersection = len(words1.intersection(words2))
    union = len(words1.union(words2))
    jaccard = intersection / union if union > 0 else 0
    
    # 2. Similaridade de caracteres (raz√£o)
    char_similarity = 1 - (abs(len(text1) - len(text2)) / max(len(text1), len(text2), 1))
    
    # 3. Combinar m√©tricas
    final_similarity = (jaccard * 0.7) + (char_similarity * 0.3)
    
    return final_similarity

def get_avg_confidence(ocr_data):
    """
    Extrai confian√ßa m√©dia dos dados do OCR.
    """
    if not ocr_data or 'conf' not in ocr_data:
        return 0
    
    confidences = [float(conf) for conf in ocr_data['conf'] if float(conf) > 0]
    return sum(confidences) / len(confidences) if confidences else 0

def intelligent_layout_detection(image) -> Dict:
    """
    Detecta layout do documento usando an√°lise avan√ßada e IA.
    Retorna informa√ß√µes sobre colunas, tabelas, cabe√ßalhos, etc.
    """
    try:
        # Converter PIL Image para numpy array se necess√°rio
        if hasattr(image, 'convert'):  # √â um objeto PIL
            image = np.array(image.convert('RGB'))
        
        # Converter para numpy array se necess√°rio
        if not isinstance(image, np.ndarray):
            image = np.array(image)
        
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) if len(image.shape) == 3 else image
        
        # 1. Detec√ß√£o de bordas para estrutura
        edges = cv2.Canny(gray, 50, 150)
        
        # 2. Detec√ß√£o de linhas horizontais e verticais
        kernel_h = cv2.getStructuringElement(cv2.MORPH_RECT, (40, 1))
        kernel_v = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 40))
        
        horizontal_lines = cv2.morphologyEx(edges, cv2.MORPH_OPEN, kernel_h)
        vertical_lines = cv2.morphologyEx(edges, cv2.MORPH_OPEN, kernel_v)
        
        # 3. An√°lise de estrutura de colunas
        h_lines = cv2.HoughLinesP(horizontal_lines, 1, np.pi/180, threshold=50, minLineLength=100, maxLineGap=10)
        v_lines = cv2.HoughLinesP(vertical_lines, 1, np.pi/180, threshold=50, minLineLength=100, maxLineGap=10)
        
        # 4. Detectar tipo de layout
        layout_info = {
            'type': 'single_column',
            'has_tables': False,
            'column_count': 1,
            'text_regions': [],
            'table_regions': [],
            'header_regions': [],
            'confidence': 0.8
        }
        
        # An√°lise de colunas baseada em espa√ßos em branco
        height, width = gray.shape
        
        # Proje√ß√£o horizontal para detectar colunas
        horizontal_projection = np.sum(gray == 255, axis=0)
        
        # Encontrar vales (espa√ßos entre colunas)
        valley_threshold = height * 0.7
        valleys = []
        
        for i in range(1, len(horizontal_projection) - 1):
            if (horizontal_projection[i] > valley_threshold and 
                horizontal_projection[i-1] < valley_threshold and 
                horizontal_projection[i+1] < valley_threshold):
                valleys.append(i)
        
        if len(valleys) >= 1:
            layout_info['type'] = 'multi_column'
            layout_info['column_count'] = len(valleys) + 1
        
        # Detectar tabelas baseado em grade de linhas
        if h_lines is not None and v_lines is not None and len(h_lines) > 3 and len(v_lines) > 3:
            layout_info['has_tables'] = True
            layout_info['type'] = 'table_mixed'
        
        # Detectar regi√µes de cabe√ßalho (parte superior da p√°gina)
        header_region = gray[:int(height * 0.15), :]
        header_density = np.sum(header_region < 200) / header_region.size
        
        if header_density > 0.1:  # Tem conte√∫do no cabe√ßalho
            layout_info['header_regions'].append({
                'bbox': (0, 0, width, int(height * 0.15)),
                'type': 'header'
            })
        
        return layout_info
        
    except Exception as e:
        print(f"Erro na detec√ß√£o de layout: {e}")
        return {
            'type': 'single_column',
            'has_tables': False,
            'column_count': 1,
            'text_regions': [],
            'confidence': 0.5
        }

def auto_perspective_correction(image: np.ndarray) -> np.ndarray:
    """
    Corre√ß√£o autom√°tica de perspectiva usando detec√ß√£o de bordas da p√°gina.
    """
    try:
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) if len(image.shape) == 3 else image
        
        # 1. Blur e threshold para encontrar contornos
        blurred = cv2.GaussianBlur(gray, (5, 5), 0)
        thresh = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]
        
        # 2. Encontrar contornos
        contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        # 3. Encontrar o maior contorno (presumivelmente a p√°gina)
        if not contours:
            return image
            
        largest_contour = max(contours, key=cv2.contourArea)
        
        # 4. Aproximar contorno para um quadril√°tero
        epsilon = 0.02 * cv2.arcLength(largest_contour, True)
        approx = cv2.approxPolyDP(largest_contour, epsilon, True)
        
        # 5. Se encontramos um quadril√°tero, corrigir perspectiva
        if len(approx) == 4:
            # Ordenar pontos: top-left, top-right, bottom-right, bottom-left
            pts = approx.reshape(4, 2)
            rect = order_points(pts)
            
            # Calcular dimens√µes da imagem de destino
            (tl, tr, br, bl) = rect
            widthA = np.sqrt(((br[0] - bl[0]) ** 2) + ((br[1] - bl[1]) ** 2))
            widthB = np.sqrt(((tr[0] - tl[0]) ** 2) + ((tr[1] - tl[1]) ** 2))
            maxWidth = max(int(widthA), int(widthB))
            
            heightA = np.sqrt(((tr[0] - br[0]) ** 2) + ((tr[1] - br[1]) ** 2))
            heightB = np.sqrt(((tl[0] - bl[0]) ** 2) + ((tl[1] - bl[1]) ** 2))
            maxHeight = max(int(heightA), int(heightB))
            
            # Destino da transforma√ß√£o
            dst = np.array([
                [0, 0],
                [maxWidth - 1, 0],
                [maxWidth - 1, maxHeight - 1],
                [0, maxHeight - 1]], dtype="float32")
            
            # Calcular matriz de transforma√ß√£o e aplicar
            M = cv2.getPerspectiveTransform(rect, dst)
            warped = cv2.warpPerspective(image, M, (maxWidth, maxHeight))
            
            return warped
        
        return image
        
    except Exception as e:
        print(f"Erro na corre√ß√£o de perspectiva: {e}")
        return image

def order_points(pts):
    """
    Ordena pontos para corre√ß√£o de perspectiva.
    """
    rect = np.zeros((4, 2), dtype="float32")
    
    # Top-left: menor soma, Bottom-right: maior soma
    s = pts.sum(axis=1)
    rect[0] = pts[np.argmin(s)]
    rect[2] = pts[np.argmax(s)]
    
    # Top-right: menor diferen√ßa, Bottom-left: maior diferen√ßa
    diff = np.diff(pts, axis=1)
    rect[1] = pts[np.argmin(diff)]
    rect[3] = pts[np.argmax(diff)]
    
    return rect

def adaptive_image_enhancement(image: np.ndarray, enhancement_level: str = "medium") -> np.ndarray:
    """
    Realce adaptativo baseado na qualidade e caracter√≠sticas da imagem.
    """
    try:
        # Analisar qualidade da imagem
        quality_metrics = analyze_image_quality(image)
        
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) if len(image.shape) == 3 else image
        enhanced = gray.copy()
        
        # Aplicar realces baseados na qualidade detectada
        if quality_metrics['is_low_contrast']:
            # Melhorar contraste para imagens com baixo contraste
            clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))
            enhanced = clahe.apply(enhanced)
        
        if quality_metrics['is_noisy']:
            # Reduzir ru√≠do
            enhanced = cv2.bilateralFilter(enhanced, 9, 75, 75)
        
        if quality_metrics['is_blurry']:
            # Aplicar sharpening para imagens borradas
            kernel = np.array([[-1, -1, -1], [-1, 9, -1], [-1, -1, -1]])
            enhanced = cv2.filter2D(enhanced, -1, kernel)
        
        if quality_metrics['is_low_resolution']:
            # Upscaling para imagens de baixa resolu√ß√£o
            enhanced = cv2.resize(enhanced, None, fx=2, fy=2, interpolation=cv2.INTER_CUBIC)
        
        # Ajustes finais baseados no n√≠vel de realce
        if enhancement_level in ["aggressive", "ultra"]:
            # Normaliza√ß√£o de intensidade
            enhanced = cv2.normalize(enhanced, None, 0, 255, cv2.NORM_MINMAX)
            
            # Corre√ß√£o gamma adaptativa
            gamma = 1.2 if quality_metrics['is_dark'] else 0.8
            enhanced = adjust_gamma(enhanced, gamma)
        
        return enhanced
        
    except Exception as e:
        print(f"Erro no realce adaptativo: {e}")
        return image

def analyze_image_quality(image: np.ndarray) -> Dict:
    """
    Analisa qualidade da imagem para determinar realces necess√°rios.
    """
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) if len(image.shape) == 3 else image
    
    metrics = {
        'is_low_contrast': False,
        'is_noisy': False,
        'is_blurry': False,
        'is_low_resolution': False,
        'is_dark': False,
        'overall_quality': 'good'
    }
    
    # 1. An√°lise de contraste
    contrast = gray.std()
    if contrast < 30:
        metrics['is_low_contrast'] = True
    
    # 2. An√°lise de ru√≠do (usando Laplaciano)
    laplacian_var = cv2.Laplacian(gray, cv2.CV_64F).var()
    if laplacian_var < 100:
        metrics['is_blurry'] = True
    
    # 3. An√°lise de resolu√ß√£o
    height, width = gray.shape
    if height < 300 or width < 300:
        metrics['is_low_resolution'] = True
    
    # 4. An√°lise de brilho
    mean_brightness = gray.mean()
    if mean_brightness < 80:
        metrics['is_dark'] = True
    
    # 5. Detec√ß√£o de ru√≠do usando gradientes
    grad_x = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)
    grad_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)
    noise_level = np.sqrt(grad_x**2 + grad_y**2).mean()
    
    if noise_level > 50:
        metrics['is_noisy'] = True
    
    # 6. Qualidade geral
    quality_score = 0
    if not metrics['is_low_contrast']: quality_score += 1
    if not metrics['is_noisy']: quality_score += 1
    if not metrics['is_blurry']: quality_score += 1
    if not metrics['is_low_resolution']: quality_score += 1
    if not metrics['is_dark']: quality_score += 1
    
    if quality_score >= 4:
        metrics['overall_quality'] = 'excellent'
    elif quality_score >= 3:
        metrics['overall_quality'] = 'good'
    elif quality_score >= 2:
        metrics['overall_quality'] = 'fair'
    else:
        metrics['overall_quality'] = 'poor'
    
    return metrics

def adjust_gamma(image, gamma=1.0):
    """
    Ajusta gamma da imagem.
    """
    inv_gamma = 1.0 / gamma
    table = np.array([((i / 255.0) ** inv_gamma) * 255 for i in np.arange(0, 256)]).astype("uint8")
    return cv2.LUT(image, table)

@app.post("/extract-text-hybrid/")
async def extract_text_hybrid_endpoint(
    file: UploadFile = File(...),
    enhancement_level: str = Form("ultra"),
    use_ai_engines: bool = Form(True),
    engine_preference: str = Form("auto")
):
    """
    Endpoint para extra√ß√£o de texto h√≠brida com tecnologias avan√ßadas.
    
    - **file**: Arquivo PDF para processamento
    - **enhancement_level**: N√≠vel de melhoria da imagem (conservative, medium, aggressive, ultra)
    - **use_ai_engines**: Usar m√∫ltiplos motores de IA (EasyOCR, TrOCR)
    - **engine_preference**: Escolher engine espec√≠fico:
        - "auto": An√°lise de consenso autom√°tica (padr√£o)
        - "tesseract": Usar apenas Tesseract
        - "easyocr": Usar apenas EasyOCR
        - "trocr": Usar apenas TrOCR
        - "consensus": For√ßar an√°lise de consenso entre todos
    
    Retorna texto extra√≠do estruturado p√°gina por p√°gina com estat√≠sticas detalhadas.
    """
    if not file.filename.lower().endswith('.pdf'):
        raise HTTPException(status_code=400, detail="Arquivo deve ser um PDF")
    
    # Validar engine_preference
    valid_engines = ["auto", "tesseract", "easyocr", "trocr", "consensus"]
    if engine_preference not in valid_engines:
        raise HTTPException(
            status_code=400, 
            detail=f"engine_preference deve ser um de: {', '.join(valid_engines)}"
        )
    
    input_pdf_path = None
    start_time = time.time()
    
    try:
        print(f"üöÄ INICIANDO SISTEMA H√çBRIDO DE OCR")
        print(f"üìÅ Arquivo: {file.filename}")
        print(f"‚öôÔ∏è N√≠vel: {enhancement_level}")
        print(f"ü§ñ IA Engines: {'Ativados' if use_ai_engines else 'Desativados'}")
        print(f"üéØ Engine preferido: {engine_preference}")
        
        # Salvar arquivo tempor√°rio
        temp_dir = "temp"
        os.makedirs(temp_dir, exist_ok=True)
        
        file_id = str(uuid.uuid4())
        input_pdf_path = os.path.join(temp_dir, f"input_{file_id}.pdf")
        
        with open(input_pdf_path, "wb") as buffer:
            content = await file.read()
            buffer.write(content)
        
        print(f"üìÑ Convertendo PDF para imagens...")
        
        # Lista de poss√≠veis caminhos do Poppler para testar
        poppler_paths = [
            None,  # Primeiro tenta o PATH do sistema
            r"C:\poppler-24.08.0\Library\bin",  # Caminho correto para a vers√£o conda
            r"C:\poppler-24.08.0\bin",
            r"C:\poppler\bin", 
            r"C:\Program Files\poppler\bin",
            r"C:\tools\poppler\bin"
        ]
        
        for poppler_path in poppler_paths:
            try:
                if poppler_path:
                    print(f"üîß Tentando poppler em: {poppler_path}")
                    images = convert_from_path(input_pdf_path, dpi=300, fmt='jpeg', poppler_path=poppler_path)
                else:
                    print(f"üîß Tentando poppler do PATH do sistema...")
                    images = convert_from_path(input_pdf_path, dpi=300, fmt='jpeg')
                print(f"‚úÖ Poppler funcionando! P√°ginas encontradas: {len(images)}")
                break
            except Exception as e:
                if poppler_path:
                    print(f"‚ùå Falha com poppler em {poppler_path}: {str(e)}")
                else:
                    print(f"‚ùå Falha com poppler do PATH: {str(e)}")
                continue
        
        if images is None:
            raise HTTPException(
                status_code=500, 
                detail="‚ùå Erro cr√≠tico: Poppler n√£o encontrado! Consulte POPPLER_INSTALACAO.md para instru√ß√µes de instala√ß√£o."
            )
        
        extracted_text = []
        total_pages = len(images)
        engines_used = set()
        total_confidence = 0
        confidence_count = 0
        
        print(f"üìä Processando {total_pages} p√°ginas...")
        
        for page_num, image in enumerate(images):
            print(f"üìÑ Processando p√°gina {page_num + 1}/{total_pages}...")
            
            # Escolher m√©todo de extra√ß√£o baseado na prefer√™ncia
            if engine_preference == "tesseract":
                # Usar apenas Tesseract
                result = extract_text_with_multiple_configs(image)
                engine_used = 'Tesseract'
                method_used = result.get('config', 'multiple_configs')
                
            elif engine_preference == "easyocr":
                # Usar apenas EasyOCR
                result = extract_text_with_easyocr_only(image)
                engine_used = 'EasyOCR'
                method_used = 'easyocr_only'
                
            elif engine_preference == "trocr":
                # Usar apenas TrOCR
                result = extract_text_with_trocr_only(image)
                engine_used = 'TrOCR'
                method_used = 'trocr_only'
                
            elif engine_preference in ["auto", "consensus"]:
                # Usar sistema h√≠brido com m√∫ltiplos motores
                if use_ai_engines:
                    result = extract_text_with_ai_engines(image)
                    engine_used = result.get('engine', 'Consensus')
                    method_used = result.get('method', 'ai_consensus')
                else:
                    # Se AI engines est√£o desativados, usar apenas Tesseract
                    result = extract_text_with_multiple_configs(image)
                    engine_used = 'Tesseract'
                    method_used = result.get('config', 'multiple_configs')
            
            engines_used.add(engine_used)
            
            # Extrair texto e confian√ßa
            texto_extraido = result.get('text', '').strip()
            confidence = result.get('confidence', 0)
            
            if confidence > 0:
                total_confidence += confidence
                confidence_count += 1
            
            # Estruturar informa√ß√µes da p√°gina
            page_info = {
                "pagina": page_num + 1,
                "texto": texto_extraido,
                "engine_usado": engine_used,
                "metodo": method_used,
                "confianca": round(confidence, 2) if confidence else 0,
                "estatisticas": {
                    "caracteres": len(texto_extraido),
                    "linhas": len(texto_extraido.split('\n')) if texto_extraido else 0,
                    "palavras": len(texto_extraido.split()) if texto_extraido else 0
                },
                "parametros": {
                    "enhancement_level": enhancement_level,
                    "engine_preference": engine_preference,
                    "use_ai_engines": use_ai_engines
                }
            }
            
            extracted_text.append(page_info)
        
        # Calcular estat√≠sticas finais
        avg_confidence = (total_confidence / confidence_count) if confidence_count > 0 else 0
        processing_time = time.time() - start_time
        
        # Contar caracteres totais
        total_characters = sum(page['estatisticas']['caracteres'] for page in extracted_text)
        total_words = sum(page['estatisticas']['palavras'] for page in extracted_text)
        
        print(f"‚úÖ PROCESSAMENTO CONCLU√çDO")
        print(f"üìä Total de caracteres extra√≠dos: {total_characters}")
        print(f"üìä Engines utilizados: {list(engines_used)}")
        
        return {
            "filename": file.filename,
            "total_paginas": total_pages,
            "texto_extraido": extracted_text,
            "configuracao_global": {
                "enhancement_level": enhancement_level,
                "engine_preference": engine_preference,
                "use_ai_engines": use_ai_engines
            },
            "estatisticas_globais": {
                "paginas_processadas": total_pages,
                "engines_utilizados": list(engines_used),
                "confianca_media": round(avg_confidence, 2),
                "tempo_processamento_segundos": round(processing_time, 2),
                "total_caracteres": total_characters,
                "total_palavras": total_words,
                "paginas_com_texto": len([p for p in extracted_text if p['texto']])
            },
            "sucesso": True
        }
        
    except HTTPException as he:
        # Re-raise HTTP exceptions
        raise he
    except Exception as e:
        print(f"‚ùå Erro cr√≠tico no sistema h√≠brido: {str(e)}")
        raise HTTPException(status_code=500, detail=f"‚ùå Erro cr√≠tico no sistema h√≠brido: {str(e)}")
    
    finally:
        # Limpeza
        if input_pdf_path and os.path.exists(input_pdf_path):
            try:
                os.remove(input_pdf_path)
            except:
                pass

def detect_skew_angle(image: np.ndarray) -> float:
    """
    Detecta o √¢ngulo de inclina√ß√£o do texto na imagem.
    """
    try:
        # Converter para escala de cinza se necess√°rio
        if len(image.shape) == 3:
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        else:
            gray = image.copy()
        
        # Aplicar threshold
        thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]
        
        # Detectar bordas
        edges = cv2.Canny(thresh, 50, 150)
        
        # Detectar linhas
        lines = cv2.HoughLinesP(edges, 1, np.pi/180, threshold=100, minLineLength=100, maxLineGap=10)
        
        if lines is not None:
            angles = []
            for line in lines:
                x1, y1, x2, y2 = line[0]
                angle = np.arctan2(y2 - y1, x2 - x1) * 180 / np.pi
                angles.append(angle)
            
            if angles:
                # Usar mediana dos √¢ngulos
                return np.median(angles)
        
        return 0.0
        
    except Exception as e:
        print(f"Erro na detec√ß√£o de skew: {e}")
        return 0.0

def rotate_image(image: np.ndarray, angle: float) -> np.ndarray:
    """
    Rotaciona a imagem pelo √¢ngulo especificado.
    """
    try:
        if abs(angle) < 0.5:
            return image
        
        (h, w) = image.shape[:2]
        center = (w // 2, h // 2)
        
        # Criar matriz de rota√ß√£o
        rotation_matrix = cv2.getRotationMatrix2D(center, angle, 1.0)
        
        # Aplicar rota√ß√£o
        rotated = cv2.warpAffine(image, rotation_matrix, (w, h), 
                                flags=cv2.INTER_CUBIC, 
                                borderMode=cv2.BORDER_REPLICATE)
        
        return rotated
        
    except Exception as e:
        print(f"Erro na rota√ß√£o: {e}")
        return image

def calculate_average_confidence(data: Dict) -> float:
    """
    Calcula a confian√ßa m√©dia dos dados do OCR.
    """
    try:
        if not data or 'conf' not in data:
            return 0.0
        
        confidences = [float(conf) for conf in data['conf'] if float(conf) > 0]
        
        if not confidences:
            return 0.0
        
        return sum(confidences) / len(confidences)
        
    except Exception as e:
        print(f"Erro no c√°lculo de confian√ßa: {e}")
        return 0.0

def extract_text_with_easyocr_only(image):
    """
    Extrai texto usando apenas EasyOCR.
    """
    global easyocr_reader
    try:
        print("\nüîç USANDO APENAS EASYOCR")
        
        # Inicializa√ß√£o LAZY do EasyOCR
        if not easyocr_reader and EASYOCR_AVAILABLE:
            try:
                global engines_loading
                engines_loading = True
                print("‚è≥ Inicializando EasyOCR sob demanda...")
                
                # Log dos diret√≥rios antes da inicializa√ß√£o
                print("üìÅ Estado do cache ANTES da inicializa√ß√£o:")
                import easyocr
                print(f"  üóÇÔ∏è EasyOCR module path: {easyocr.__file__}")
                
                # Verificar onde o EasyOCR salva por padr√£o
                easyocr_default_path = os.path.expanduser('~/.EasyOCR')
                print(f"  üóÇÔ∏è EasyOCR default path: {easyocr_default_path}")
                
                if os.path.exists(easyocr_default_path):
                    files = os.listdir(easyocr_default_path)
                    print(f"  üìÇ {easyocr_default_path}: {len(files)} arquivos")
                
                # Garantir que o EasyOCR use nosso cache
                easyocr_cache_dir = '/app/.cache/easyocr'
                os.makedirs(easyocr_cache_dir, exist_ok=True)
                
                print(f"üîß For√ßando EasyOCR a usar: {easyocr_cache_dir}")
                easyocr_reader = easyocr.Reader(['pt', 'en'], gpu=False, model_storage_directory=easyocr_cache_dir)
                
                # Log dos diret√≥rios AP√ìS a inicializa√ß√£o
                print("üìÅ Estado do cache AP√ìS a inicializa√ß√£o:")
                for cache_dir in ['/app/.cache', '/app/.cache/easyocr', easyocr_default_path]:
                    if os.path.exists(cache_dir):
                        files = os.listdir(cache_dir)
                        print(f"  üìÇ {cache_dir}: {len(files)} arquivos")
                        if files:
                            print(f"    üìÑ Primeiros arquivos: {files[:3]}")
                
                print("‚úÖ EasyOCR inicializado com sucesso")
                engines_loading = False
            except Exception as e:
                engines_loading = False
                print(f"‚ùå Erro ao inicializar EasyOCR: {e}")
                return {
                    'text': '',
                    'confidence': 0.0,
                    'engine': 'EasyOCR',
                    'method': 'initialization_error'
                }
        
        if not easyocr_reader:
            print("‚ùå EasyOCR n√£o est√° dispon√≠vel")
            return {
                'text': '',
                'confidence': 0.0,
                'engine': 'EasyOCR',
                'method': 'unavailable'
            }
        
        # Converter imagem para formato adequado
        try:
            if hasattr(image, 'convert'):  # PIL Image
                image_array = np.array(image)
            else:
                image_array = image
            
            # Reduzir tamanho da imagem se muito grande (economizar mem√≥ria)
            height, width = image_array.shape[:2]
            max_dimension = 2000  # Limitar a 2000px
            
            if height > max_dimension or width > max_dimension:
                print(f"üîß Redimensionando imagem de {width}x{height} para economizar mem√≥ria...")
                scale = max_dimension / max(height, width)
                new_width = int(width * scale)
                new_height = int(height * scale)
                image_array = cv2.resize(image_array, (new_width, new_height), interpolation=cv2.INTER_LANCZOS4)
                print(f"‚úÖ Nova dimens√£o: {new_width}x{new_height}")
            
            print("üîÑ Executando EasyOCR.readtext()...")
            start_time = time.time()
            easyocr_results = easyocr_reader.readtext(image_array)
            processing_time = time.time() - start_time
            print(f"‚úÖ EasyOCR processou {len(easyocr_results) if easyocr_results else 0} regi√µes em {processing_time:.2f}s")
        except Exception as e:
            print(f"‚ùå Erro durante readtext: {e}")
            return {
                'text': '',
                'confidence': 0.0,
                'engine': 'EasyOCR',
                'method': 'execution_error'
            }
        
        if easyocr_results:
            easyocr_text = ' '.join([result[1] for result in easyocr_results])
            easyocr_confidence = sum([result[2] for result in easyocr_results]) / len(easyocr_results) * 100
            
            print(f"‚úÖ EasyOCR - Confian√ßa: {easyocr_confidence:.1f}%")
            print(f"üìù Texto extra√≠do (primeiros 200 chars): {easyocr_text[:200]}...")
            
            # Limpeza de mem√≥ria
            del image_array, easyocr_results
            gc.collect()
            
            return {
                'text': easyocr_text,
                'confidence': easyocr_confidence,
                'engine': 'EasyOCR',
                'method': 'neural_network'
            }
        else:
            print("‚ùå EasyOCR - Nenhum texto detectado")
            return {
                'text': '',
                'confidence': 0.0,
                'engine': 'EasyOCR',
                'method': 'no_text_detected'
            }
            
    except Exception as e:
        print(f"‚ùå EasyOCR - Erro: {e}")
        return {
            'text': '',
            'confidence': 0.0,
            'engine': 'EasyOCR',
            'method': 'error'
        }

def extract_text_with_trocr_only(image):
    """
    Extrai texto usando apenas TrOCR.
    """
    global trocr_processor, trocr_model
    try:
        print("\nüîç USANDO APENAS TrOCR")
        
        # Inicializa√ß√£o LAZY do TrOCR
        if (not trocr_processor or not trocr_model) and TRANSFORMERS_AVAILABLE and TORCH_AVAILABLE:
            try:
                global engines_loading
                engines_loading = True
                print("‚è≥ Inicializando TrOCR sob demanda...")
                trocr_processor = TrOCRProcessor.from_pretrained("microsoft/trocr-base-handwritten")
                trocr_model = VisionEncoderDecoderModel.from_pretrained("microsoft/trocr-base-handwritten")
                print("‚úÖ TrOCR inicializado com sucesso")
                engines_loading = False
            except Exception as e:
                engines_loading = False
                print(f"‚ùå Erro ao inicializar TrOCR: {e}")
                return {
                    'text': '',
                    'confidence': 0.0,
                    'engine': 'TrOCR',
                    'method': 'initialization_error'
                }
        
        if not trocr_processor or not trocr_model:
            print("‚ùå TrOCR n√£o est√° dispon√≠vel")
            return {
                'text': '',
                'confidence': 0.0,
                'engine': 'TrOCR',
                'method': 'unavailable'
            }
        
        from PIL import Image as PILImage
        
        # Converter para PIL Image adequadamente
        if isinstance(image, np.ndarray):
            # Se √© numpy array, converter para PIL
            if image.dtype != np.uint8:
                image = (image * 255).astype(np.uint8)
            pil_image = PILImage.fromarray(image)
        elif hasattr(image, 'convert'):  # J√° √© PIL Image
            pil_image = image
        else:
            # Tentar converter de qualquer outro tipo
            pil_image = PILImage.fromarray(np.array(image))
        
        # Garantir que est√° em RGB
        if pil_image.mode != 'RGB':
            pil_image = pil_image.convert('RGB')
        
        pixel_values = trocr_processor(pil_image, return_tensors="pt").pixel_values
        generated_ids = trocr_model.generate(pixel_values)
        trocr_text = trocr_processor.batch_decode(generated_ids, skip_special_tokens=True)[0]
        
        if trocr_text.strip():
            # TrOCR n√£o fornece confian√ßa direta, estimamos baseado no tamanho e qualidade
            trocr_confidence = min(95.0, len(trocr_text.strip()) * 2.5)
            
            print(f"‚úÖ TrOCR - Confian√ßa estimada: {trocr_confidence:.1f}%")
            print(f"üìù Texto extra√≠do (primeiros 200 chars): {trocr_text[:200]}...")
            
            return {
                'text': trocr_text,
                'confidence': trocr_confidence,
                'engine': 'TrOCR',
                'method': 'transformer'
            }
        else:
            print("‚ùå TrOCR - Nenhum texto detectado")
            return {
                'text': '',
                'confidence': 0.0,
                'engine': 'TrOCR',
                'method': 'no_text_detected'
            }
            
    except Exception as e:
        print(f"‚ùå TrOCR - Erro: {e}")
        return {
            'text': '',
            'confidence': 0.0,
            'engine': 'TrOCR',
            'method': 'error'
        }

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000) 